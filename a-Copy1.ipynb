{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a107dfc6-dd33-4f60-823b-dfeb0d051b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.select import Select\n",
    "from time import sleep\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "driver = webdriver.Chrome('/Users/glicia/python/chromedriver')\n",
    "\n",
    "url = 'https://www.drugs.com/sfx/'\n",
    "driver.get(url)\n",
    "\n",
    "ses = []\n",
    "\n",
    "#この範囲は変更しない\n",
    "elem_range = driver.find_elements_by_class_name('ddc-clearfix')[1]\n",
    "#Aの範囲\n",
    "elem_range2 = elem_range.find_element_by_css_selector('#a-to-z > div > div:nth-child(1) > ul:nth-child(2)')\n",
    "\n",
    "for elem in elem_range2.find_elements_by_tag_name('li'):\n",
    "    driver.execute_script(\"arguments[0].scrollIntoView();\", elem)\n",
    "    sleep(0.9)\n",
    "    atag1 = elem.find_element_by_tag_name('a')\n",
    "    new_url = atag1.get_attribute('href')\n",
    "\n",
    "    driver.execute_script(\"window.open()\")\n",
    "    driver.switch_to.window(driver.window_handles[1])\n",
    "    driver.get(new_url)\n",
    "    sleep(0.9)\n",
    "    \n",
    "    #二つ目のタブ\n",
    "    dg_range = driver.find_element_by_class_name('ddc-list-column-2')\n",
    "    for dg_elem in dg_range.find_elements_by_tag_name('li'):\n",
    "        driver.execute_script(\"arguments[0].scrollIntoView();\", dg_elem)\n",
    "        sleep(0.9)\n",
    "\n",
    "        atag2 = dg_elem.find_element_by_tag_name('a')\n",
    "        dn = atag2.text\n",
    "        ltst_url = atag2.get_attribute('href')\n",
    "        \n",
    "        res = requests.get(ltst_url)\n",
    "        soup = BeautifulSoup(res.text, 'html.parser')\n",
    "        drug_name = soup.find('h1').text\n",
    "        dn = drug_name.split(' Side Effects')[0]\n",
    "        try:\n",
    "            gntxt = soup.find('p', class_='drug-subtitle').text\n",
    "            gn = gntxt.split('Generic name: ')[1]\n",
    "        except:\n",
    "            gn = dn\n",
    "            \n",
    "        try:\n",
    "            soup.find('h3', text='Side effects requiring immediate medical attention').name = 'new_tag'\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        try:\n",
    "            soup.find('h3', text='Side effects not requiring immediate medical attention').name = 'new_tag'\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        try:\n",
    "            ntgs = soup.find_all('new_tag')\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        try:\n",
    "            for el in ntgs:\n",
    "                els = [i for i in itertools.takewhile(lambda x : x.name not in [el.name, 'h2'], el.next_siblings)]\n",
    "                border = soup.new_tag('border')\n",
    "                el.wrap(border)\n",
    "                for tag in els:\n",
    "                    border.append(tag)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        #<i>と<ul>の抜き出しに成功\n",
    "        se_list = []\n",
    "        for j in soup.find_all('border'):\n",
    "            try:\n",
    "                rng_name = j.find('new_tag').text\n",
    "            except:\n",
    "                rng_name = 'N/A'\n",
    "            for i in soup.find_all('i'):\n",
    "                try:\n",
    "                    if i.parent.next_sibling.next_sibling and i.parent.next_sibling.next_sibling.name == 'ul':\n",
    "                        #print(i)\n",
    "                        #print(i.parent.next_sibling.next_sibling)\n",
    "                        fqecy = i.text\n",
    "                        for se in i.parent.next_sibling.next_sibling.find_all('li'):\n",
    "                            sename = se.text\n",
    "                            se_list = [dn, gn, rng_name, fqecy, sename]\n",
    "                            ses.append(se_list)\n",
    "                except:\n",
    "                    pass\n",
    "                \n",
    "    driver.close()\n",
    "    driver.switch_to.window(driver.window_handles[0])\n",
    "driver.quit()\n",
    "df = pd.DataFrame(ses, columns=['Drug_Name', 'Generic_Name', 'Requiring_Level', 'Frequency', 'Side_Effect'])\n",
    "df.to_csv('dn_a_test20211220.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61a7dc0f-3bba-4945-abfe-ef0d3e555db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9abc439e-3118-463e-bf26-01b42712fc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(ses, columns=['Drug_Name', 'Generic_Name', 'Requiring_Level', 'Frequency', 'Side_Effect'])\n",
    "df.to_csv('dn_a_test20211220.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21b79d7-c1e4-49c7-acd1-fc098149a417",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
